# ADR-004: Задание 4. Реализация ETL с использованием Spring Batch
## Автор: Сурков Александр
## Дата: 19.09.2025

## 1. Контекст
Столкнувшись с проблемами производительности, TradeWare начала подготовку к миграции в микрсервисную архитектуру.  

Монолит БД перенесли на Google Cloud Platform (GCP), а хостинг файлов с отчётами — в Google Cloud Storage (GCS).  

Однако отсутствие пакетной обработки приводит к необходимости обрабатывать каждую запись отдельно в «онлайн-режиме», что негативно сказывается на производительности всей системы: 
- Обновления остатков в БД идут построчно, что перегружает транзакционные ресурсы.
- Отчётность формируется в реальном времени, хотя её можно унести в ночную пакетную обработку.
- API для взаимодействия с логистическими партнёрами и региональными складами страдают от задержек и взаимного блокирования, когда один поток данных тормозит все остальные.
- В случае ошибок трудно отследить причину её возникновения и свести имеющиеся логи и метрики в одну картину.
- Как вы видите, у TradeWare прямо назрела необходимость внедрить пакетную обработку данных и систему мониторинга и оповещения. Так можно будет разгрузить онлайн-компоненты, повысить стабильность в пиковые периоды и масштабировать системы при росте бизнеса.

```plantuml
@startuml
!includeurl https://raw.githubusercontent.com/SurkovAleksandr/MSA-AgroTech-sprint-1/refs/heads/master/c4_model/C4_Context.puml
!includeurl https://raw.githubusercontent.com/SurkovAleksandr/MSA-AgroTech-sprint-1/refs/heads/master/c4_model/C4_Container.puml

SHOW_PERSON_OUTLINE()

title Диаграмма С4 текущего сценария обработки загружаемого отчета

Person(employee, "Сотрудник склада", "Использует web-приложение загрузки отчетов")
Container(webApp, "UI", "JS, Angular", "Приложение для пользователя, Web-интерфейс")
System_Boundary(system, "Backend GCP/ComputeEngine") {
    Container(reportLogic, "Backend", "WildFly/Java", "Сервер с Java-приложением содержащим логику обработки отчетов")
    ContainerDb(dbNomenclature, "БД номенклатуры", "PostgresSQL", "Актуальные данные о наличии товаров на складах")
    ContainerDb(dbReferenceData, "БД справочных данных о товарах", "PostgresSQL", "Данные характеристиках товаров, промо-акциях и т.д")
    ContainerDb(fileStorage, "Файловое хранилище", "Google cloud storage", "Загруженные файлы отчетов")
}

Rel_D(employee, webApp, "использует", "HTTP/HTTPS")
Rel_R(webApp, reportLogic, "вызывает", "REST API JSON/HTTP")
Rel_U(reportLogic, dbNomenclature, "получение и запись данных", "SQL")
Rel_R(reportLogic, dbReferenceData, "получение и запись данных", "SQL")
Rel_D(reportLogic, fileStorage, "работа с файлами", "REST API")

@enduml
```

Пояснения к схеме:
- Пользователь на основе Excel-шаблона формирует отчёт по остаткам и сохраняет его как CSV-файл. Поэтому первичная валидация формата данных происходит на уровне Excel-шаблона.
- Пользователь запускает загрузку полученного CSV-файла через интерфейс ERP:
  1. Файл проходит дополнительную валидацию на уровне Java-приложения. В случае ошибки пользователь получает ответ в браузере: «Ошибка формата загружаемых данных».
  2. Файл сохраняется в хранилище в GCS.
  3. Запускается процесс обработки файла, обновление значениями из БД справочных данных и сохранения данных в БД номенклатуры.
  4. Если операция обработки завершается успешно, то пользователь получает уведомление об этом.
- Пользователь дожидается успешного завершения загрузки.
- При ошибке в формате данных пользователь вносит необходимые исправления в отчёт и повторяет загрузку.

## 2. Требования
Промежуточное состояние (через пару месяцев): сформирован план, как решить уже имеющиеся проблемы с производительностью системы, в частности — подготовить её к росту объёма обрабатываемых данных.  

Ключевые направления:
- Обеспечение надёжной работы под возрастающей нагрузкой. Предполагаемая нагрузка — 100-150 параллельных загрузок в пиковые часы. Также нужна возможность гибко масштабироваться под нагрузкой.
- Соблюдение требований к производительности: среднее время обработки отчета на 2 000 строк составляет до 30 секунд.
- Внедрения системы централизованного сбора логов и метрик.
- Формирования решение для дальнейшей миграции в микросервисную архитектуру. Оно должно позволить постепенно вынести функционал из монолита в развёрнутые рядом сервисы, интегрироваться с Java-экосистемой и внедрять инструменты логирования и мониторинга, которые будут удобно сочетаться с микросервисной архитектурой.

## 3. Решение
1. Добавление WebSocket между UI и Backend. Когда пользователь загружает в систему отчет он ждет ответа от сервера. Ответ занимает до 30 секунд. Это связано с тем, что на Backend происходит несколько операций: 
   - сохранение отчета в GCS
   - валидация отчета
   - обработка и сохранение в "БД номенклатуры"
   Чтобы пользователь не ждал ответа добавим между UI и Backend протокол взаимодействия WebSocket. Когда обработка завершится, пользователь получит на UI сообщение об этом.  
 
   Дополнительно добавим нотификацию через Telegram и email.
2. Сервисы по обработки отчета + Kafka.   
   Когда пользователь отправляет отчет в систему, отчет сохраняется в GCS и пользователю возвращается ответ о том, что отчет принят.
 
   Чтобы обработать отчет, выделим из основного Backend'а микросервис по обработки отчетов на основе Spring Batch. Когда основной Backend сохранит отчет в GCS он отправит сообщение в Kafka(добавляем брокер сообщений).
 
   Топик с сообщениями будет читать новый микросервис по обработки отчетов. Когда он обработает отчет он через другой топик сообщит об этом сервисам:
   - основному Backend'у, чтобы он по WebSocket сообщил об этом на UI
   - по отправки сообщений в Telegram и email
3. Добавление сервисов отправки сообщений в Telegram и email. Чтобы пользователь не ждал ответа от системы, а получал нотификации добавим:
   - сервис для отправки сообщений в Telegram и связанную с сервисом БД 
   - сервис для отправки сообщений по email и связанную с сервисом БД
4. Выделить сервисы для:
   - БД номенклатуры
   - БД справочных данных о товарах
   - Файловое хранилище
5. Системы централизованного сбора логов и метрик.

Основным шагом по ускорению обработки отчетов является п.2. В условиях ограниченных ресурсов можно вынести в отдельный микросервис только обработку отчетов и вызывать этот сервис синхронно.

Но для дальнейшего увеличения производительности и масштабируемости необходимо вводить асинхронную обработку, разбивать монолит по микросервисам.
Централизованный мониторинг и логирование можно реализовывать параллельно силами DevOps. 

Для решения о том, надо ли убирать сервис Backend и как это делать не хватает данных. Возможно в нем еще есть нужный функционал. 

Предлагаемое архитектурное решение  
```plantuml
@startuml
!includeurl https://raw.githubusercontent.com/SurkovAleksandr/MSA-AgroTech-sprint-1/refs/heads/master/c4_model/C4_Context.puml
!includeurl https://raw.githubusercontent.com/SurkovAleksandr/MSA-AgroTech-sprint-1/refs/heads/master/c4_model/C4_Container.puml

SHOW_PERSON_OUTLINE()

title Диаграмма С4 текущего сценария обработки загружаемого отчета

Person(employee, "Сотрудник склада", "Использует web-приложение загрузки отчетов")
Container(webApp, "UI", "JS, Angular", "Приложение для пользователя, Web-интерфейс")
System_Boundary(system, "Backend GCP/ComputeEngine") {
    Container(backend, "Backend", "WildFly/Java", "Сервер с Java-приложением содержащим логику обработки отчетов")

    Container(nomenclature, "Сервис номенклатуры", "Java/Spring", "Обработка данных о наличии товаров на складах")
    ContainerDb(nomenclatureDB, "БД номенклатуры", "PostgresSQL", "Актуальные данные о наличии товаров на складах")

    Container(referenceData, "Сервис справочных данных о товарах", "Java/Spring", "Работа с характеристиками товаров, промо-акциях и т.д")
    ContainerDb(referenceDataDB, "БД справочных данных о товарах", "PostgresSQL", "Данные характеристиках товаров, промо-акциях и т.д")
    
    Container(fileStorage, "Файловое хранилище", "Java/Spring", "Загрузка/получение файлов отчетов")
    ContainerDb(fileStorageDB, "Файловое хранилище", "Google cloud storage", "Загруженные файлы отчетов")

    Container(reportProcessing, "Обработка отчета", "Java/Spring Batch", "Валидация и обработка отчета")
    ContainerDb(reportProcessingDB, "Данные по обработке отчета", "PostgresSQL", "Информация по обработанным отчетам")

    Container(telegramNotification, "Нотификация через Telegram", "Java", "Отправка сообщений пользователям в Telegram")
    ContainerDb(telegramNotificationDB, "Сообщения в Telegram", "MongoDB", "Cообщения пользователям в Telegram")

    Container(emailNotification, "Нотификация через email", "Java", "Отправка сообщений пользователям по email")
    ContainerDb(emailNotificationDB, "Сообщения по email", "MongoDB", "Cообщения пользователям по email")

    Container(kafka, "Передача сообщений", "Kafka", "Передача сообщений")

    Container(prometheus, "Сбор метрик", "Prometheus", "Сбор метрик о работе сервисов")
    Container(elk, "Сбор логов", "ELK", "Сбор логов о работе сервисов")
}

Rel_R(employee, webApp, "использует", "HTTP/HTTPS")
Rel_D(webApp, backend, "вызывает", "REST API JSON/HTTP")
Rel_U(backend, webApp, "отправляет", "WebSocket")

Rel(backend, nomenclature, "получение и запись данных", "REST API")
Rel_U(nomenclature, nomenclatureDB, "получение и запись данных", "SQL")

Rel_R(backend, referenceData, "получение и запись данных", "REST API")
Rel_R(referenceData, referenceDataDB, "получение и запись данных", "SQL")

Rel_D(backend, fileStorage, "работа с файлами", "REST API")
Rel_D(fileStorage, fileStorageDB, "работа с файлами", "REST API")

Rel(backend, kafka, "отправляет", "kafka")
Rel(kafka, backend, "получает", "kafka")
Rel(kafka, reportProcessing, "получае", "kafka")
Rel(reportProcessing, kafka, "отправляет", "kafka")
Rel(reportProcessing, reportProcessingDB, "сохранение", "JDBC")
Rel(reportProcessing, fileStorage, "Получение отчетов", "REST API")
Rel(reportProcessing, nomenclature, "Обновление номенклатуры", "REST API")

Rel(kafka, telegramNotification, "получае", "kafka")
Rel(kafka, emailNotification, "получае", "kafka")

Rel(telegramNotification, telegramNotificationDB, "сохранение", "MongoDB")
Rel(emailNotification, emailNotificationDB, "сохранение", "MongoDB")

@enduml
```  

## 4. Альтернативы
- Apache Airflow. Лучше подходит для обработки больших объемов данных и сложной зависимостью процедур обработки
- Kubernetes CronJob. Если результаты обработки данных не нужны в режиме реального времени. 

## 5. Недостатки, ограничения, риски
- обрабатываемы отчеты небольшие. Если потребуется обрабатывать большие объемы данных подход со Spring Batch может не подойти.
- нет инструментов визуального контроля выполнения шагов обработки
- необходимо логировать ключевые параметры при обработке данных, чтобы в случае сбое легче разбираться в причинах
- большое количество шагов в обработке может сильно усложнить поддержку

