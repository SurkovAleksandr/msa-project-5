services:
  postgresdb:
    image: postgres:17.5
    restart: unless-stopped
    env_file: ./.env
    environment:
      - POSTGRES_USER=$POSTGRESDB_USER
      - POSTGRES_PASSWORD=$POSTGRESDB_ROOT_PASSWORD
      - POSTGRES_DB=$POSTGRESDB_DATABASE
    ports:
      - $POSTGRESDB_LOCAL_PORT:$POSTGRESDB_DOCKER_PORT

  elasticsearch:
    image: 'docker.elastic.co/elasticsearch/elasticsearch:7.17.28'
    platform: linux/amd64
    container_name: 'elasticsearch'
    restart: 'unless-stopped'
    ports:
      - '9200:9200'
      - '9300:9300'
    environment:
      - 'discovery.type=single-node'
      - 'xpack.security.enabled=false'
      - 'ES_JAVA_OPTS=-Xms512m -Xmx512m'
    healthcheck:
      test: 'curl -f http://localhost:9200 || exit 1'

  logstash:
    image: 'docker.elastic.co/logstash/logstash:7.17.28'
    container_name: 'logstash'
    restart: 'unless-stopped'
    ports:
      - '5044:5044'
    volumes:
      - './logstash/pipeline:/usr/share/logstash/pipeline/'
    depends_on:
      - 'elasticsearch'
    healthcheck:
      test: 'curl -f http://localhost:9600 || exit 1'

  kibana:
    image: 'docker.elastic.co/kibana/kibana:7.17.28'
    container_name: 'kibana'
    restart: 'unless-stopped'
    ports:
      - '5601:5601'
    environment:
      - 'ELASTICSEARCH_HOSTS=http://elasticsearch:9200'
    depends_on:
      - 'elasticsearch'
    healthcheck:
      test: 'curl -f http://localhost:5601 || exit 1'

  filebeat:
    build: 'filebeat'
    container_name: 'filebeat'
    restart: 'unless-stopped'
    volumes:
      - '/var/run/docker.sock:/var/run/docker.sock'
      - '/var/lib/docker/containers:/usr/share/dockerlogs/data:ro'
    depends_on:
      - 'elasticsearch'
      - 'logstash'

  prometheus:
    image: 'prom/prometheus:v3.4.0'
    container_name: 'prometheus'
    restart: 'unless-stopped'
    volumes:
      - './prometheus/prometheus.yml:/etc/prometheus/prometheus.yml'
      - './prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml'
    ports:
      - '9090:9090'
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "9090" ]

  grafana:
    image: 'grafana/grafana:12.0.1'
    container_name: 'grafana'
    restart: 'unless-stopped'
    ports:
      - '3000:3000'
    environment:
      - 'GF_USERS_ALLOW_SIGN_UP=false'
    volumes:
      - './grafana/provisioning:/etc/grafana/provisioning'
    depends_on:
      - 'prometheus'
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "3000" ]

  # prometheus работает по принципу pull, т.е. сам забирает метрики.
  # Для Spring Batch это не подходит, т.к. приложение завершается и метрики результата работы
  # могут не попасть в prometheus.
  # Чтобы этого избежать можно самому приложению публиковать метрики в промежуточный сервис.
  # Для prometheus это pushgateway.
  pushgateway:
    image: prom/pushgateway:v1.11.1
    ports:
      - 9091:9091

  alertmanager:
    image: prom/alertmanager:v0.28.0
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - ./alertmanager/templates:/etc/alertmanager/templates
      - alertmanager-data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--log.level=debug'
      - '--web.external-url=http://localhost:9093'
    depends_on:
      - prometheus

  app:
    depends_on:
      - postgresdb
      - filebeat
      - grafana
    image: batch-processing
    build:
      context: .
      dockerfile: ./Dockerfile
    ports:
      - 8080:8080
    restart: no

volumes:
  alertmanager-data: